[('spark.databricks.preemption.enabled', 'true'),
 ('spark.databricks.clusterUsageTags.clusterFirstOnDemand', '1'),
 ('spark.sql.hive.metastore.jars', '/databricks/databricks-hive/*'),
 ('spark.driver.tempDirectory', '/local_disk0/tmp'),
 ('spark.sql.warehouse.dir', 'dbfs:/user/hive/warehouse'),
 ('spark.databricks.clusterUsageTags.dataPlaneRegion', 'us-east-1'),
 ('spark.databricks.managedCatalog.clientClassName',
  'com.databricks.managedcatalog.ManagedCatalogClientImpl'),
 ('spark.databricks.credential.scope.fs.gs.auth.access.tokenProviderClassName',
  'com.databricks.backend.daemon.driver.credentials.CredentialScopeGCPTokenProvider'),
 ('spark.databricks.clusterUsageTags.clusterTargetWorkers', '1'),
 ('spark.hadoop.fs.fcfs-s3.impl.disable.cache', 'true'),
 ('spark.hadoop.fs.s3a.retry.limit', '20'),
 ('spark.databricks.clusterUsageTags.clusterAvailability',
  'SPOT_WITH_FALLBACK'),
 ('spark.databricks.service.dbutils.repl.backend',
  'com.databricks.dbconnect.ReplDBUtils'),
 ('spark.sql.streaming.checkpointFileManagerClass',
  'com.databricks.spark.sql.streaming.DatabricksCheckpointFileManager'),
 ('spark.hadoop.databricks.s3.verifyBucketExists.enabled', 'false'),
 ('spark.streaming.driver.writeAheadLog.allowBatching', 'true'),
 ('spark.databricks.clusterSource', 'UI'),
 ('spark.hadoop.hive.server2.transport.mode', 'http'),
 ('spark.databricks.acl.dfAclsEnabled', 'false'),
 ('spark.hadoop.fs.cpfs-adl.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.hailEnabled', 'false'),
 ('spark.hadoop.databricks.s3.amazonS3Client.cache.enabled', 'true'),
 ('spark.databricks.clusterUsageTags.clusterLogDeliveryEnabled', 'false'),
 ('spark.databricks.clusterUsageTags.containerType', 'LXC'),
 ('spark.databricks.clusterUsageTags.clusterLastActivityTime',
  '1721299910306'),
 ('spark.hadoop.fs.s3a.assumed.role.credentials.provider',
  'shaded.databricks.org.apache.hadoop.fs.s3a.DatabricksInstanceProfileCredentialsProvider'),
 ('spark.eventLog.enabled', 'false'),
 ('spark.databricks.clusterUsageTags.isIMv2Enabled', 'false'),
 ('spark.hadoop.fs.stage.impl.disable.cache', 'true'),
 ('spark.hadoop.hive.hmshandler.retry.interval', '2000'),
 ('spark.executor.tempDirectory', '/local_disk0/tmp'),
 ('spark.hadoop.fs.azure.authorization.caching.enable', 'false'),
 ('spark.hadoop.fs.fcfs-abfss.impl',
  'com.databricks.sql.acl.fs.FixedCredentialsFileSystem'),
 ('spark.hadoop.mapred.output.committer.class',
  'com.databricks.backend.daemon.data.client.DirectOutputCommitter'),
 ('spark.hadoop.hive.server2.thrift.http.port', '10000'),
 ('spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version', '2'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2S3', '0'),
 ('spark.sql.allowMultipleContexts', 'false'),
 ('spark.databricks.eventLog.enabled', 'true'),
 ('spark.home', '/databricks/spark'),
 ('spark.repl.class.uri', 'spark://10.99.77.10:35325/classes'),
 ('spark.hadoop.hive.server2.idle.operation.timeout', '7200000'),
 ('spark.task.reaper.enabled', 'true'),
 ('spark.storage.memoryFraction', '0.5'),
 ('spark.databricks.clusterUsageTags.sparkImageLabel',
  'release__11.3.x-snapshot-scala2.12__databricks-universe__11.3.37__30a500b__fae6d7c__jenkins__d6bafec__format-3'),
 ('spark.databricks.sql.configMapperClass',
  'com.databricks.dbsql.config.SqlConfigMapperBridge'),
 ('spark.driver.maxResultSize', '4g'),
 ('spark.databricks.clusterUsageTags.shardName', 'nvirginia-prod'),
 ('spark.databricks.clusterUsageTags.sparkEnvVarContainsNewline', 'false'),
 ('spark.hadoop.fs.fcfs-s3.impl',
  'com.databricks.sql.acl.fs.FixedCredentialsFileSystem'),
 ('spark.databricks.delta.multiClusterWrites.enabled', 'true'),
 ('spark.worker.cleanup.enabled', 'false'),
 ('spark.sql.legacy.createHiveTableByDefault', 'false'),
 ('spark.databricks.driver.preferredMavenCentralMirrorUrl',
  'https://maven-central.storage-download.googleapis.com/maven2/'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2File', '0'),
 ('spark.hadoop.fs.fcfs-s3a.impl.disable.cache', 'true'),
 ('spark.ui.port', '40001'),
 ('spark.app.id', 'app-20240718122407-0000'),
 ('spark.hadoop.fs.s3a.attempts.maximum', '10'),
 ('spark.databricks.clusterUsageTags.enableCredentialPassthrough', 'false'),
 ('spark.databricks.clusterUsageTags.sparkEnvVarContainsDollarSign', 'false'),
 ('spark.databricks.clusterUsageTags.userProvidedRemoteVolumeType',
  'ebs_volume_type: GENERAL_PURPOSE_SSD\n'),
 ('spark.databricks.clusterUsageTags.enableJdbcAutoStart', 'true'),
 ('spark.hadoop.fs.azure.user.agent.prefix', ''),
 ('spark.hadoop.fs.s3n.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.enableGlueCatalogCredentialPassthrough',
  'false'),
 ('spark.executor.memory', '20396m'),
 ('spark.databricks.clusterUsageTags.driverContainerPrivateIp', '10.99.77.10'),
 ('spark.hadoop.fs.fcfs-s3n.impl',
  'com.databricks.sql.acl.fs.FixedCredentialsFileSystem'),
 ('spark.hadoop.fs.s3a.retry.throttle.interval', '500ms'),
 ('spark.hadoop.fs.wasb.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.clusterLogDestination', ''),
 ('spark.databricks.wsfsPublicPreview', 'true'),
 ('spark.master', 'spark://10.99.77.10:7077'),
 ('spark.cleaner.referenceTracking.blocking', 'false'),
 ('spark.databricks.clusterUsageTags.isSingleUserCluster', 'false'),
 ('spark.databricks.clusterUsageTags.clusterState', 'Pending'),
 ('spark.databricks.clusterUsageTags.sparkEnvVarContainsSingleQuotes',
  'false'),
 ('spark.databricks.tahoe.logStore.azure.class',
  'com.databricks.tahoe.store.AzureLogStore'),
 ('spark.hadoop.fs.azure.skip.metrics', 'true'),
 ('spark.hadoop.hive.hmshandler.retry.attempts', '10'),
 ('spark.hadoop.javax.jdo.option.ConnectionUserName', 'edlmeta'),
 ('spark.scheduler.mode', 'FAIR'),
 ('spark.sql.sources.default', 'delta'),
 ('spark.databricks.unityCatalog.credentialManager.tokenRefreshEnabled',
  'true'),
 ('spark.app.startTime', '1721305442275'),
 ('spark.hadoop.fs.cpfs-s3n.impl',
  'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem'),
 ('spark.hadoop.fs.cpfs-adl.impl',
  'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem'),
 ('spark.hadoop.fs.fcfs-s3n.impl.disable.cache', 'true'),
 ('spark.hadoop.fs.cpfs-abfss.impl',
  'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem'),
 ('spark.databricks.clusterUsageTags.clusterNumCustomTags', '1'),
 ('spark.databricks.passthrough.oauth.refresher.impl',
  'com.databricks.backend.daemon.driver.credentials.OAuthTokenRefresherClient'),
 ('spark.driver.host', '10.99.77.10'),
 ('spark.sql.hive.metastore.sharedPrefixes',
  'org.mariadb.jdbc,com.mysql.jdbc,org.postgresql,com.microsoft.sqlserver,microsoft.sql.DateTimeOffset,microsoft.sql.Types,com.databricks,com.codahale,com.fasterxml.jackson,shaded.databricks'),
 ('spark.databricks.io.directoryCommit.enableLogicalDelete', 'false'),
 ('spark.task.reaper.killTimeout', '60s'),
 ('spark.hadoop.parquet.block.size.row.check.min', '10'),
 ('spark.databricks.clusterUsageTags.clusterMinWorkers', '1'),
 ('spark.hadoop.hive.server2.use.SSL', 'true'),
 ('spark.hadoop.fs.mcfs-s3a.impl',
  'com.databricks.sql.acl.fs.ManagedCatalogFileSystem'),
 ('spark.hadoop.databricks.dbfs.client.version', 'v2'),
 ('spark.databricks.clusterUsageTags.userProvidedRemoteVolumeSizeGb', '0'),
 ('spark.hadoop.fs.s3a.canned.acl', 'BucketOwnerFullControl'),
 ('spark.hadoop.hive.server2.keystore.path',
  '/databricks/keys/jetty-ssl-driver-keystore.jks'),
 ('spark.databricks.clusterUsageTags.instanceProfileUsed', 'true'),
 ('spark.databricks.credential.redactor',
  'com.databricks.logging.secrets.CredentialRedactorProxyImpl'),
 ('spark.databricks.clusterUsageTags.clusterPinned', 'false'),
 ('spark.databricks.acl.provider',
  'com.databricks.sql.acl.ReflectionBackedAclProvider'),
 ('spark.databricks.wsfs.workspacePrivatePreview', 'true'),
 ('spark.databricks.mlflow.autologging.enabled', 'true'),
 ('spark.extraListeners',
  'com.databricks.backend.daemon.driver.DBCEventLoggingListener'),
 ('spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.enabled',
  'false'),
 ('spark.databricks.sparkContextId', '2027585355949817534'),
 ('spark.sql.parquet.cacheMetadata', 'true'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Abfss', '0'),
 ('spark.hadoop.parquet.abfs.readahead.optimization.enabled', 'true'),
 ('spark.databricks.clusterUsageTags.clusterMaxWorkers', '2'),
 ('spark.hadoop.fs.adl.impl', 'com.databricks.adl.AdlFileSystem'),
 ('spark.hadoop.fs.cpfs-abfss.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.enableLocalDiskEncryption', 'false'),
 ('spark.databricks.tahoe.logStore.class',
  'com.databricks.tahoe.store.DelegatingLogStore'),
 ('spark.hadoop.fs.s3.impl.disable.cache', 'true'),
 ('spark.hadoop.spark.hadoop.aws.glue.cache.db.ttl-mins', '30'),
 ('spark.databricks.workspaceUrl', 'deere-edl.cloud.databricks.com'),
 ('spark.hadoop.spark.hadoop.aws.glue.cache.table.ttl-mins', '30'),
 ('libraryDownload.sleepIntervalSeconds', '5'),
 ('spark.databricks.cloudProvider', 'AWS'),
 ('spark.sql.hive.convertMetastoreParquet', 'true'),
 ('spark.executor.id', 'driver'),
 ('spark.databricks.service.dbutils.server.backend',
  'com.databricks.dbconnect.SparkServerDBUtils'),
 ('spark.databricks.repl.enableClassFileCleanup', 'true'),
 ('spark.databricks.clusterUsageTags.clusterId', '0110-181359-fs149yfq'),
 ('spark.hadoop.fs.s3a.multipart.size', '10485760'),
 ('spark.databricks.clusterUsageTags.cloudProvider', 'AWS'),
 ('spark.databricks.clusterUsageTags.effectiveSparkVersion',
  '11.3.x-scala2.12'),
 ('spark.metrics.conf', '/databricks/spark/conf/metrics.properties'),
 ('spark.akka.frameSize', '256'),
 ('spark.hadoop.fs.s3a.fast.upload', 'true'),
 ('spark.hadoop.fs.wasbs.impl',
  'shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem'),
 ('spark.sql.streaming.stopTimeout', '15s'),
 ('spark.hadoop.hive.server2.keystore.password', '[REDACTED]'),
 ('spark.databricks.clusterUsageTags.ignoreTerminationEventInAlerting',
  'false'),
 ('spark.databricks.clusterUsageTags.sparkEnvVarContainsEscape', 'false'),
 ('spark.databricks.overrideDefaultCommitProtocol',
  'org.apache.spark.sql.execution.datasources.SQLHadoopMapReduceCommitProtocol'),
 ('spark.worker.aioaLazyConfig.dbfsReadinessCheckClientClass',
  'com.databricks.backend.daemon.driver.NephosDbfsReadinessCheckClient'),
 ('spark.databricks.clusterUsageTags.clusterNoDriverDaemon', 'false'),
 ('libraryDownload.timeoutSeconds', '180'),
 ('spark.hadoop.parquet.memory.pool.ratio', '0.5'),
 ('spark.databricks.clusterUsageTags.clusterOwnerUserId', '5074956154514546'),
 ('spark.databricks.passthrough.adls.gen2.tokenProviderClassName',
  'com.databricks.backend.daemon.data.client.adl.AdlGen2CredentialContextTokenProvider'),
 ('spark.hadoop.fs.s3a.block.size', '67108864'),
 ('spark.databricks.clusterUsageTags.workerEnvironmentId',
  'workerenv-701067943002101-3f7b0a09-0889-4619-a98d-f0acc60b39ce'),
 ('spark.databricks.tahoe.logStore.gcp.class',
  'com.databricks.tahoe.store.GCPLogStore'),
 ('spark.databricks.clusterUsageTags.orgId', '701067943002101'),
 ('spark.serializer.objectStreamReset', '100'),
 ('spark.r.sql.derby.temp.dir', '/tmp/Rtmp41tvwR'),
 ('spark.databricks.clusterUsageTags.sparkMasterUrlType', 'None'),
 ('spark.databricks.passthrough.enabled', 'false'),
 ('spark.sql.sources.commitProtocolClass',
  'com.databricks.sql.transaction.directory.DirectoryAtomicCommitProtocol'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Gcs', '0'),
 ('spark.hadoop.fs.fcfs-s3a.impl',
  'com.databricks.sql.acl.fs.FixedCredentialsFileSystem'),
 ('spark.databricks.clusterUsageTags.attribute_tag_budget', ''),
 ('fs.s3a.server-side-encryption-algorithm', 'AES256'),
 ('spark.databricks.clusterUsageTags.clusterPythonVersion', '3'),
 ('spark.databricks.clusterUsageTags.enableDfAcls', 'false'),
 ('spark.databricks.cloudfetch.requestDownloadUrlsWithHeaders', 'true'),
 ('spark.databricks.clusterUsageTags.userProvidedRemoteVolumeCount', '0'),
 ('spark.shuffle.service.enabled', 'true'),
 ('spark.hadoop.fs.file.impl',
  'com.databricks.backend.daemon.driver.WorkspaceLocalFileSystem'),
 ('spark.hadoop.fs.fcfs-wasb.impl.disable.cache', 'true'),
 ('spark.hadoop.fs.cpfs-s3.impl',
  'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem'),
 ('spark.databricks.clusterUsageTags.containerZoneId', 'auto'),
 ('spark.databricks.clusterUsageTags.driverInstanceId', 'i-085de36e0cb85d254'),
 ('spark.databricks.clusterUsageTags.attribute_tag_dust_maintainer', ''),
 ('spark.hadoop.fs.s3a.multipart.threshold', '104857600'),
 ('spark.rpc.message.maxSize', '256'),
 ('spark.databricks.clusterUsageTags.clusterOwnerOrgId', '701067943002101'),
 ('spark.databricks.clusterUsageTags.attribute_tag_dust_suite', ''),
 ('spark.hadoop.fs.fcfs-wasbs.impl',
  'com.databricks.sql.acl.fs.FixedCredentialsFileSystem'),
 ('spark.databricks.clusterUsageTags.clusterWorkers', '1'),
 ('spark.databricks.driverNfs.enabled', 'true'),
 ('spark.databricks.clusterUsageTags.clusterMetastoreAccessType',
  'RDS_DIRECT'),
 ('spark.hadoop.parquet.page.metadata.validation.enabled', 'true'),
 ('spark.databricks.acl.enabled', 'false'),
 ('spark.databricks.unityCatalog.credentialManager.apiTokenProviderClassName',
  'com.databricks.unity.TokenServiceApiTokenProvider'),
 ('spark.databricks.passthrough.glue.executorServiceFactoryClassName',
  'com.databricks.backend.daemon.driver.credentials.GlueClientExecutorServiceFactory'),
 ('spark.databricks.clusterUsageTags.awsWorkspaceIMDSV2EnablementStatus',
  'false'),
 ('spark.hadoop.fs.gs.impl',
  'shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemHadoop3'),
 ('spark.databricks.clusterUsageTags.enableElasticDisk', 'true'),
 ('spark.databricks.acl.scim.client',
  'com.databricks.spark.sql.acl.client.DriverToWebappScimClient'),
 ('spark.databricks.clusterUsageTags.sparkEnvVarContainsBacktick', 'false'),
 ('spark.hadoop.fs.adl.impl.disable.cache', 'true'),
 ('spark.driver.port', '35325'),
 ('spark.hadoop.parquet.block.size.row.check.max', '10'),
 ('spark.hadoop.fs.s3a.connection.maximum', '200'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2', '0'),
 ('spark.hadoop.fs.s3a.fast.upload.active.blocks', '32'),
 ('spark.shuffle.reduceLocality.enabled', 'false'),
 ('spark.hadoop.spark.sql.sources.outputCommitterClass',
  'com.databricks.backend.daemon.data.client.MapReduceDirectOutputCommitter'),
 ('spark.hadoop.fs.fcfs-abfs.impl',
  'com.databricks.sql.acl.fs.FixedCredentialsFileSystem'),
 ('spark.databricks.clusterUsageTags.instanceWorkerEnvId',
  'workerenv-701067943002101-3f7b0a09-0889-4619-a98d-f0acc60b39ce'),
 ('spark.hadoop.fs.fcfs-abfss.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.clusterName', 'FINANCE_CQ_CLUSTER'),
 ('spark.hadoop.hive.server2.thrift.http.cookie.auth.enabled', 'false'),
 ('spark.hadoop.spark.hadoop.aws.glue.cache.table.size', '1000'),
 ('spark.sql.parquet.compression.codec', 'snappy'),
 ('spark.hadoop.fs.stage.impl',
  'com.databricks.backend.daemon.driver.managedcatalog.PersonalStagingFileSystem'),
 ('spark.databricks.credential.scope.fs.s3a.tokenProviderClassName',
  'com.databricks.backend.daemon.driver.credentials.CredentialScopeS3TokenProvider'),
 ('spark.databricks.clusterUsageTags.autoTerminationMinutes', '30'),
 ('spark.databricks.cloudfetch.hasRegionSupport', 'true'),
 ('spark.databricks.clusterUsageTags.ngrokNpipEnabled', 'true'),
 ('spark.hadoop.databricks.s3.create.deleteUnnecessaryFakeDirectories',
  'false'),
 ('spark.databricks.clusterUsageTags.clusterGeneration', '1166'),
 ('spark.hadoop.fs.wasb.impl',
  'shaded.databricks.org.apache.hadoop.fs.azure.NativeAzureFileSystem'),
 ('spark.hadoop.fs.s3a.impl',
  'shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystemHadoop3'),
 ('spark.databricks.clusterUsageTags.sparkVersion', '11.3.x-scala2.12'),
 ('spark.hadoop.spark.hadoop.aws.glue.cache.db.size', '1000'),
 ('spark.databricks.unityCatalog.enabled', 'false'),
 ('spark.hadoop.fs.abfs.impl',
  'shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemHadoop3'),
 ('spark.databricks.passthrough.glue.credentialsProviderFactoryClassName',
  'com.databricks.backend.daemon.driver.credentials.DatabricksCredentialProviderFactory'),
 ('spark.databricks.clusterUsageTags.clusterEbsVolumeSize', '0'),
 ('spark.sparklyr-backend.threads', '1'),
 ('spark.hadoop.avro.mapred.ignore.inputs.without.extension', 'false'),
 ('spark.hadoop.fs.fcfs-wasb.impl',
  'com.databricks.sql.acl.fs.FixedCredentialsFileSystem'),
 ('spark.databricks.passthrough.s3a.tokenProviderClassName',
  'com.databricks.backend.daemon.driver.aws.AwsCredentialContextTokenProvider'),
 ('spark.databricks.session.share', 'false'),
 ('spark.databricks.clusterUsageTags.clusterResourceClass', 'default'),
 ('spark.databricks.clusterUsageTags.driverInstancePrivateIp', '10.99.81.177'),
 ('spark.hadoop.fs.s3n.impl',
  'shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystemHadoop3'),
 ('spark.databricks.isShieldWorkspace', 'false'),
 ('spark.hadoop.fs.idbfs.impl', 'com.databricks.io.idbfs.IdbfsFileSystem'),
 ('spark.driver.extraJavaOptions',
  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED'),
 ('spark.databricks.telemetry.prometheus.samplingRate', '100'),
 ('spark.hadoop.fs.dbfs.impl',
  'com.databricks.backend.daemon.data.client.DbfsHadoop3'),
 ('spark.databricks.clusterUsageTags.clusterSku', 'STANDARD_SKU'),
 ('spark.hadoop.fs.gs.impl.disable.cache', 'true'),
 ('spark.hadoop.fs.s3.impl',
  'shaded.databricks.org.apache.hadoop.fs.s3a.S3AFileSystemHadoop3'),
 ('spark.hadoop.javax.jdo.option.ConnectionURL',
  'jdbc:mariadb://databricks-metastore-cluster.cluster-clmjhxqixqf8.us-east-1.rds.amazonaws.com:3306/edlmetastore'),
 ('spark.databricks.clusterUsageTags.userId', '5074956154514546'),
 ('spark.databricks.privateLinkEnabled', 'false'),
 ('spark.delta.sharing.profile.provider.class',
  'io.delta.sharing.DeltaSharingCredentialsProvider'),
 ('spark.executor.extraJavaOptions',
  '-XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=512m -XX:+UseCodeCacheFlushing -XX:PerMethodRecompilationCutoff=-1 -XX:PerBytecodeRecompilationCutoff=-1 -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -XX:+PrintGCDetails -verbose:gc -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Dcom.google.cloud.spark.bigquery.repackaged.io.netty.tryReflectionSetAccessible=true -Dlog4j2.formatMsgNoLookups=true -Ddatabricks.serviceName=spark-executor-1'),
 ('spark.databricks.clusterUsageTags.region', 'us-east-1'),
 ('spark.databricks.clusterUsageTags.isGroupCluster', 'false'),
 ('spark.worker.aioaLazyConfig.iamReadinessCheckClientClass',
  'com.databricks.backend.daemon.driver.NephosIamRoleCheckClient'),
 ('spark.databricks.clusterUsageTags.clusterEbsVolumeType',
  'GENERAL_PURPOSE_SSD'),
 ('spark.databricks.clusterUsageTags.clusterScalingType', 'autoscaling'),
 ('spark.databricks.automl.serviceEnabled', 'true'),
 ('spark.databricks.clusterUsageTags.clusterNodeType', 'i3.xlarge'),
 ('spark.hadoop.parquet.page.size.check.estimate', 'false'),
 ('spark.databricks.clusterUsageTags.attribute_tag_service', ''),
 ('spark.databricks.passthrough.s3a.threadPoolExecutor.factory.class',
  'com.databricks.backend.daemon.driver.aws.S3APassthroughThreadPoolExecutorFactory'),
 ('spark.databricks.delta.preview.enabled', 'true'),
 ('spark.databricks.metrics.filesystem_io_metrics', 'true'),
 ('spark.databricks.cloudfetch.requesterClassName',
  'com.databricks.spark.sql.cloudfetch.DataDaemonCloudPresignedUrlRequester'),
 ('spark.databricks.clusterUsageTags.driverContainerId',
  '962c88e6073547f2ad896bf79e8c35d6'),
 ('spark.databricks.delta.logStore.crossCloud.fatal', 'true'),
 ('spark.databricks.driverNfs.clusterWidePythonLibsEnabled', 'true'),
 ('spark.databricks.workerNodeTypeId', 'i3.xlarge'),
 ('spark.files.fetchFailure.unRegisterOutputOnHost', 'true'),
 ('spark.databricks.clusterUsageTags.enableSqlAclsOnly', 'false'),
 ('spark.databricks.clusterUsageTags.clusterEbsVolumeCount', '0'),
 ('spark.databricks.clusterUsageTags.clusterSizeType', 'VM_CONTAINER'),
 ('spark.hadoop.databricks.fs.perfMetrics.enable', 'true'),
 ('spark.databricks.clusterUsageTags.clusterNumSshKeys', '0'),
 ('spark.hadoop.fs.gs.outputstream.upload.chunk.size', '16777216'),
 ('spark.speculation.quantile', '0.9'),
 ('spark.databricks.clusterUsageTags.privateLinkEnabled', 'false'),
 ('spark.shuffle.manager', 'SORT'),
 ('spark.files.overwrite', 'true'),
 ('spark.databricks.credential.aws.secretKey.redactor',
  'com.databricks.spark.util.AWSSecretKeyRedactorProxy'),
 ('spark.hadoop.fs.s3a.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.sparkEnvVarContainsDoubleQuotes',
  'false'),
 ('spark.r.numRBackendThreads', '1'),
 ('spark.hadoop.fs.wasbs.impl.disable.cache', 'true'),
 ('spark.hadoop.javax.jdo.option.ConnectionPassword', '3dlPassword1'),
 ('spark.hadoop.fs.abfss.impl.disable.cache', 'true'),
 ('spark.hadoop.fs.azure.cache.invalidator.type',
  'com.databricks.encryption.utils.CacheInvalidatorImpl'),
 ('spark.databricks.clusterUsageTags.currentAttemptContainerZoneId',
  'us-east-1c'),
 ('spark.sql.hive.metastore.version', '0.13.0'),
 ('spark.shuffle.service.port', '4048'),
 ('spark.databricks.acl.client',
  'com.databricks.spark.sql.acl.client.SparkSqlAclClient'),
 ('spark.streaming.driver.writeAheadLog.closeFileAfterWrite', 'true'),
 ('spark.hadoop.hive.warehouse.subdir.inherit.perms', 'false'),
 ('spark.databricks.clusterUsageTags.runtimeEngine', 'STANDARD'),
 ('spark.databricks.clusterUsageTags.isServicePrincipalCluster', 'false'),
 ('spark.databricks.credential.scope.fs.impl',
  'com.databricks.sql.acl.fs.CredentialScopeFileSystem'),
 ('spark.databricks.enablePublicDbfsFuse', 'false'),
 ('spark.hadoop.fs.fcfs-wasbs.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.numPerGlobalInitScriptsV2', '1'),
 ('spark.databricks.passthrough.adls.tokenProviderClassName',
  'com.databricks.backend.daemon.data.client.adl.AdlCredentialContextTokenProvider'),
 ('spark.app.name', 'Databricks Shell'),
 ('spark.driver.allowMultipleContexts', 'false'),
 ('spark.databricks.driverNodeTypeId', 'i3.xlarge'),
 ('spark.hadoop.fs.AbstractFileSystem.gs.impl',
  'shaded.databricks.com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS'),
 ('spark.databricks.secret.sparkConf.keys.toRedact', ''),
 ('spark.databricks.clusterUsageTags.clusterPolicyId', '9C600A29CE00024E'),
 ('spark.rdd.compress', 'true'),
 ('spark.hadoop.spark.databricks.io.parquet.verifyChecksumOnWrite.throwsException',
  'false'),
 ('spark.databricks.python.defaultPythonRepl', 'ipykernel'),
 ('spark.databricks.clusterUsageTags.attribute_tag_dust_execution_env', ''),
 ('spark.databricks.eventLog.dir', 'eventlogs'),
 ('spark.databricks.credential.scope.fs.adls.gen2.tokenProviderClassName',
  'com.databricks.backend.daemon.driver.credentials.CredentialScopeADLSTokenProvider'),
 ('spark.databricks.clusterUsageTags.isDpCpPrivateLinkEnabled', 'false'),
 ('spark.databricks.clusterUsageTags.clusterUnityCatalogMode', 'NONE'),
 ('spark.databricks.driverNfs.pathSuffix', '.ephemeral_nfs'),
 ('spark.hadoop.javax.jdo.option.ConnectionDriverName',
  'org.mariadb.jdbc.Driver'),
 ('spark.databricks.clusterUsageTags.clusterCreator', 'Webapp'),
 ('spark.speculation', 'false'),
 ('spark.hadoop.hive.server2.session.check.interval', '60000'),
 ('spark.sql.hive.convertCTAS', 'true'),
 ('spark.repl.class.outputDir',
  '/local_disk0/tmp/repl/spark-2027585355949817534-02495840-975a-4319-bab0-3c2ced7bd114'),
 ('spark.hadoop.spark.sql.parquet.output.committer.class',
  'org.apache.spark.sql.parquet.DirectParquetOutputCommitter'),
 ('spark.hadoop.fs.s3a.max.total.tasks', '1000'),
 ('spark.databricks.tahoe.logStore.aws.class',
  'com.databricks.tahoe.store.MultiClusterLogStore'),
 ('spark.hadoop.fs.s3a.fast.upload.default', 'true'),
 ('spark.hadoop.fs.mlflowdbfs.impl',
  'com.databricks.mlflowdbfs.MlflowdbfsFileSystem'),
 ('spark.databricks.eventLog.listenerClassName',
  'com.databricks.backend.daemon.driver.DBCEventLoggingListener'),
 ('spark.hadoop.fs.abfs.impl.disable.cache', 'true'),
 ('spark.speculation.multiplier', '3'),
 ('spark.storage.blockManagerTimeoutIntervalMs', '300000'),
 ('spark.hadoop.spark.driverproxy.customHeadersToProperties',
  'X-Databricks-User-Token:spark.databricks.token,X-Databricks-Non-UC-User-Token:spark.databricks.non.uc.token,X-Databricks-Api-Url:spark.databricks.api.url,X-Databricks-ADLS-Gen1-Token:spark.databricks.adls.gen1.token,X-Databricks-ADLS-Gen2-Token:spark.databricks.adls.gen2.token,X-Databricks-Synapse-Token:spark.databricks.synapse.token,X-Databricks-AWS-Credentials:spark.databricks.aws.creds,X-Databricks-User-Id:spark.databricks.user.id,X-Databricks-User-Name:spark.databricks.user.name,X-Databricks-Workload-Id:spark.databricks.workload.id,X-Databricks-Workload-Class:spark.databricks.workload.name'),
 ('spark.sparkr.use.daemon', 'false'),
 ('spark.scheduler.listenerbus.eventqueue.capacity', '20000'),
 ('spark.databricks.clusterUsageTags.clusterStateMessage', 'Starting Spark'),
 ('spark.databricks.clusterUsageTags.clusterHasPolicy', 'true'),
 ('spark.hadoop.parquet.page.write-checksum.enabled', 'true'),
 ('spark.hadoop.databricks.s3commit.client.sslTrustAll', 'false'),
 ('spark.hadoop.fs.s3a.threads.max', '136'),
 ('spark.r.backendConnectionTimeout', '604800'),
 ('spark.ui.prometheus.enabled', 'true'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Dbfs', '0'),
 ('spark.databricks.clusterUsageTags.clusterAllTags',
  '[{"key":"component","value":"FinanceCQTag"},{"key":"Vendor","value":"Databricks"},{"key":"Creator","value":"GaliottoRaizaN@JohnDeere.com"},{"key":"ClusterName","value":"FINANCE_CQ_CLUSTER"},{"key":"ClusterId","value":"0110-181359-fs149yfq"},{"key":"Name","value":"workerenv-701067943002101-3f7b0a09-0889-4619-a98d-f0acc60b39ce-worker"}]'),
 ('spark.hadoop.fs.abfss.impl',
  'shaded.databricks.azurebfs.org.apache.hadoop.fs.azurebfs.SecureAzureBlobFileSystemHadoop3'),
 ('spark.hadoop.hive.server2.idle.session.timeout', '900000'),
 ('spark.databricks.redactor',
  'com.databricks.spark.util.DatabricksSparkLogRedactorProxy'),
 ('spark.hadoop.fs.s3a.acl.default', 'BucketOwnerFullControl'),
 ('spark.executor.extraClassPath',
  '/databricks/spark/dbconf/log4j/executor:/databricks/spark/dbconf/jets3t/:/databricks/spark/dbconf/hadoop:/databricks/hive/conf:/databricks/jars/*'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Volumes', '0'),
 ('spark.databricks.clusterUsageTags.numPerClusterInitScriptsV2Workspace',
  '0'),
 ('spark.hadoop.fs.fcfs-abfs.impl.disable.cache', 'true'),
 ('spark.databricks.clusterUsageTags.instanceBootstrapType',
  'vm-selfbootstrap'),
 ('spark.hadoop.parquet.page.verify-checksum.enabled', 'true'),
 ('spark.databricks.clusterUsageTags.instanceProfileArn',
  'arn:aws:iam::844652101329:instance-profile/collibra/EDG-FINANCECQ'),
 ('spark.logConf', 'true'),
 ('spark.databricks.clusterUsageTags.enableJobsAutostart', 'true'),
 ('spark.hadoop.hive.server2.enable.doAs', 'false'),
 ('spark.databricks.clusterUsageTags.userProvidedSparkVersion',
  '11.3.x-scala2.12'),
 ('spark.hadoop.parquet.filter.columnindex.enabled', 'false'),
 ('spark.databricks.clusterUsageTags.driverNodeType', 'i3.xlarge'),
 ('spark.shuffle.memoryFraction', '0.2'),
 ('spark.databricks.clusterUsageTags.instanceWorkerEnvNetworkType', 'byo-vpc'),
 ('spark.hadoop.fs.dbfsartifacts.impl',
  'com.databricks.backend.daemon.data.client.DBFSV1'),
 ('spark.hadoop.fs.cpfs-s3a.impl',
  'com.databricks.sql.acl.fs.CredentialPassthroughFileSystem'),
 ('spark.hadoop.fs.s3a.connection.timeout', '50000'),
 ('spark.databricks.secret.envVar.keys.toRedact', ''),
 ('spark.databricks.clusterUsageTags.clusterSpotBidPricePercent', '100'),
 ('spark.files.useFetchCache', 'false')]
